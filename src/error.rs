use nalgebra::DVector;
use serde::{Deserialize, Serialize};
use std::error::Error;
use varpro::prelude::*;
use varpro::solvers::levmar::{LevMarProblemBuilder, LevMarSolver};

const VERBOSE: bool = false;

#[derive(Debug, Clone)]
pub enum ErrorCalculation {
    Tanh,
}

/// Datatype to save and read binned simulation output.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BinData {
    temp: f64,
    binning_step: u32,
    variance: f64, // The square of the standard deviation
    std: f64,
    error: f64,
}

/// A wrapper for the observables generated by the Markov chain.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ObsChain(Vec<f64>);

impl ObsChain {
    pub fn new(vec: Vec<f64>) -> Self {
        ObsChain(vec)
    }

    fn calculate_mean_value(&self) -> f64 {
        self.0.iter().sum::<f64>() / self.0.len() as f64
    }

    fn calulate_variance(&self) -> f64 {
        let mean = self.calculate_mean_value();

        self.0.iter().map(|&x| (x - mean) * (x - mean)).sum::<f64>() / (self.0.len() as f64)
    }

    // By iteratively averaging two adjacent data points we intend to find the true error
    pub fn binning(&mut self) -> Self {
        let new_len: usize = self.0.len() / 2;
        let mut new_set: Vec<f64> = Vec::with_capacity(new_len);

        for index in 0..new_len {
            let first: f64 = self.0[index * 2];

            let mean: f64 = if let Some(second) = self.0.get((index * 2) + 1) {
                (first + second) / 2.0
            } else {
                continue;
            };

            new_set.push(mean);
        }

        ObsChain(new_set)
    }

    pub fn get_error_tanh(
        self,
        temp: f64,
        ignore_last_few_steps: usize,
    ) -> Result<f64, Box<dyn Error>> {
        let bindata_ary = self.calculate_binnings(temp, ignore_last_few_steps);
        bindata_ary.calculate_binned_error_tanh()
    }

    /// Processes the data into binnings
    pub fn calculate_binnings(mut self, temp: f64, ignore_last_few_steps: usize) -> BinDataAry {
        let mut results: Vec<BinData> = Vec::new();
        let original_length: usize = self.0.len();

        let mut binning_step: u32 = 0;
        while 2_usize.pow(binning_step) < original_length {
            // Printing
            results.push(self.get_bindata(temp, binning_step));

            // Binning
            self = self.binning();
            binning_step += 1;
        }

        for _ in 0..ignore_last_few_steps {
            results.pop();
        }

        BinDataAry(results)
    }

    /// Calcualtes ```BinData```, which includes temp, the binning step, variance, std and the error.
    pub fn get_bindata(&self, temp: f64, binning_step: u32) -> BinData {
        // Calculating the relevant values
        let variance: f64 = self.calulate_variance();
        let std: f64 = variance.sqrt();
        let error: f64 = std / ((self.0.len() - 1) as f64).sqrt();

        BinData {
            temp,
            binning_step,
            variance,
            std,
            error,
        }
    }
}

/// Wrapper for the data generated from the
#[derive(Debug, Clone)]
pub struct BinDataAry(Vec<BinData>);

impl IntoIterator for BinDataAry {
    type Item = BinData;
    type IntoIter = std::vec::IntoIter<Self::Item>;
    fn into_iter(self) -> Self::IntoIter {
        self.0.into_iter()
    }
}

impl BinDataAry {
    pub fn calculate_binned_error_tanh(self) -> Result<f64, Box<dyn Error>> {
        let mut x_values: Vec<f64> = self.0.iter().map(|data| data.binning_step as f64).collect();
        let mut y_values: Vec<f64> = self.into_iter().map(|data| data.error).collect();

        // We cannot have NaN in our y-values.
        while y_values.last().is_some_and(|y| y.is_nan()) {
            y_values.pop();
            x_values.pop();
        }

        (x_values.len() == y_values.len())
            .then(|| ())
            .ok_or("x- and y-values are of different length")?;

        let x = DVector::from_vec(x_values);
        let y = DVector::from_vec(y_values);

        fn nonlin_fn(x: &DVector<f64>, c: f64, d: f64) -> DVector<f64> {
            x.map(|x| (c * x + d).tanh())
        }

        fn nonlin_fn_dc(x: &DVector<f64>, c: f64, d: f64) -> DVector<f64> {
            x.map(|x| (1.0 - (c * x + d).tanh().powi(2)) * x)
        }

        fn nonlin_fn_dd(x: &DVector<f64>, c: f64, d: f64) -> DVector<f64> {
            x.map(|x| 1.0 - (c * x + d).tanh().powi(2))
        }

        let model = SeparableModelBuilder::<f64>::new(&["c", "d"])
            .function(&["c", "d"], nonlin_fn)
            .partial_deriv("c", nonlin_fn_dc)
            .partial_deriv("d", nonlin_fn_dd)
            .invariant_function(|x| DVector::from_element(x.len(), 1.0))
            .build()?;

        let problem = LevMarProblemBuilder::new()
            .model(&model)
            .x(x)
            .y(y)
            .initial_guess(&[0.2, 0.0])
            .build()?;

        let (solved_problem, report) = LevMarSolver::new().minimize(problem);
        report
            .termination
            .was_successful()
            .then(|| ())
            .ok_or("Termination failed")?;
        let alpha = solved_problem.params();
        let coeff = solved_problem
            .linear_coefficients()
            .ok_or("Linear coeff unwrap failed")?;

        if VERBOSE {
            println!("{alpha}");
            println!("{coeff}");
        }

        let res: f64 = coeff.into_iter().sum();

        Ok(res)
    }
}
