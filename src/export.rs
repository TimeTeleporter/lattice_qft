use std::{error::Error, fs::File};

use nalgebra::DVector;
use serde::{Deserialize, Serialize};
use varpro::prelude::*;
use varpro::solvers::levmar::{LevMarProblemBuilder, LevMarSolver};

pub trait CsvData {
    fn read_write_csv(self, path: &str) -> Result<(), Box<dyn Error>>;
    fn overwrite_csv(self, path: &str) -> Result<(), Box<dyn Error>>;
    fn fetch_csv_data(path: &str) -> Result<Vec<Self>, Box<dyn Error>>
    where
        Self: Sized;
}

impl<T> CsvData for T
where
    T: Serialize + for<'a> Deserialize<'a>,
{
    fn read_write_csv(self, path: &str) -> Result<(), Box<dyn Error>> {
        // Initialize data storage
        let mut storage: Vec<T> = Vec::new();

        read_from_csv(path, &mut storage)?;

        // Append the new entry
        storage.push(self);

        // Write to the file
        write_to_csv(path, storage)?;

        Ok(())
    }

    fn overwrite_csv(self, path: &str) -> Result<(), Box<dyn Error>> {
        // Initialize data storage
        let mut storage: Vec<T> = Vec::new();

        // Append the new entry
        storage.push(self);

        write_to_csv(path, storage)?;

        Ok(())
    }

    fn fetch_csv_data(path: &str) -> Result<Vec<T>, Box<dyn Error>> {
        let mut storage: Vec<T> = Vec::new();

        read_from_csv(path, &mut storage)?;

        Ok(storage)
    }
}

fn write_to_csv<T>(path: &str, storage: Vec<T>) -> Result<(), Box<dyn Error>>
where
    T: Serialize + for<'a> Deserialize<'a>,
{
    let mut wtr = csv::Writer::from_path(path)?;
    for data in storage {
        wtr.serialize(data)?;
    }
    wtr.flush()?;
    Ok(())
}

fn read_from_csv<T>(path: &str, storage: &mut Vec<T>) -> Result<(), Box<dyn Error>>
where
    T: Serialize + for<'a> Deserialize<'a>,
{
    let file = File::open(path)?;
    let mut rdr = csv::Reader::from_reader(file);
    Ok(for result in rdr.deserialize() {
        let test_data: T = result?;
        storage.push(test_data);
    })
}

pub fn clean_csv(path: &str) -> Result<(), Box<dyn Error>> {
    let storage: Vec<()> = Vec::new();
    write_to_csv(path, storage)?;
    Ok(())
}

// ----------------------------------------------------------------------------

/// Datatype to save and read simulation output.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SimResult {
    temp: f64,
    burnin: usize,
    iterations: usize,
    observable: f64,
    error: Option<f64>,
}

impl SimResult {
    pub fn new(
        temp: f64,
        burnin: usize,
        iterations: usize,
        observable: f64,
        error: Option<f64>,
    ) -> Self {
        SimResult {
            temp,
            burnin,
            iterations,
            observable,
            error,
        }
    }

    pub fn set_error(&mut self, error_option: Option<f64>) {
        self.error = error_option;
    }
}

/// Datatype to save and read binned simulation output.
#[derive(Debug, Serialize, Deserialize)]
pub struct BinData {
    temp: f64,
    binning_step: u32,
    variance: f64, // The square of the standard deviation
    std: f64,
    error: f64,
}

/// A wrapper for the Markov chain elements generated by the Metropolis simulation.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ObsChain(Vec<f64>);

impl ObsChain {
    pub fn new(vec: Vec<f64>) -> Self {
        ObsChain(vec)
    }

    pub fn calculate_mean_value(&self) -> f64 {
        self.0.iter().sum::<f64>() / self.0.len() as f64
    }

    pub fn calulate_variance(&self) -> f64 {
        let mean = self.calculate_mean_value();

        self.0.iter().map(|&x| (x - mean) * (x - mean)).sum::<f64>() / (self.0.len() as f64)
    }

    // By iteratively averaging two adjacent data points we intend to find the true error
    pub fn binning(&mut self) -> Self {
        let new_len: usize = self.0.len() / 2;
        let mut new_set: Vec<f64> = Vec::with_capacity(new_len);

        for index in 0..new_len {
            let first: f64 = self.0[index * 2];

            let mean: f64 = if let Some(second) = self.0.get((index * 2) + 1) {
                (first + second) / 2.0
            } else {
                continue;
            };

            new_set.push(mean);
        }

        ObsChain(new_set)
    }

    /// Processes the data into binnings
    pub fn calculate_binnings(mut self, temp: f64, ignore_last_few_steps: usize) -> Vec<BinData> {
        let mut results: Vec<BinData> = Vec::new();
        let original_length: usize = self.0.len();

        let mut binning_step: u32 = 0;
        while 2_usize.pow(binning_step) < original_length {
            // Printing
            results.push(self.get_bindata(temp, binning_step));

            // Binning
            self = self.binning();
            binning_step += 1;
        }

        for _ in 0..ignore_last_few_steps {
            results.pop();
        }

        results
    }

    /// Calcualtes ```BinData```, which includes temp, the binning step, variance, std and the error.
    pub fn get_bindata(&self, temp: f64, binning_step: u32) -> BinData {
        // Calculating the relevant values
        let variance: f64 = self.calulate_variance();
        let std: f64 = variance.sqrt();
        let error: f64 = std / ((self.0.len() - 1) as f64).sqrt();

        BinData {
            temp,
            binning_step,
            variance,
            std,
            error,
        }
    }
}

pub fn calculate_binned_error(bindata_ary: &Vec<BinData>) -> Result<f64, Box<dyn Error>> {
    let mut x_values: Vec<f64> = bindata_ary
        .iter()
        .map(|data| data.binning_step as f64)
        .collect();
    let mut y_values: Vec<f64> = bindata_ary.into_iter().map(|data| data.error).collect();

    // We cannot have NaN in our y-values.
    while y_values.last().is_some_and(|y| y.is_nan()) {
        y_values.pop();
        x_values.pop();
    }

    (x_values.len() == y_values.len())
        .then(|| ())
        .ok_or("x- and y-values are of different length")?;

    let x = DVector::from_vec(x_values);
    let y = DVector::from_vec(y_values);

    fn nonlin_fn(x: &DVector<f64>, c: f64, d: f64) -> DVector<f64> {
        x.map(|x| (c * x + d).tanh())
    }

    fn nonlin_fn_dc(x: &DVector<f64>, c: f64, d: f64) -> DVector<f64> {
        x.map(|x| (1.0 - (c * x + d).tanh().powi(2)) * x)
    }

    fn nonlin_fn_dd(x: &DVector<f64>, c: f64, d: f64) -> DVector<f64> {
        x.map(|x| 1.0 - (c * x + d).tanh().powi(2))
    }

    let model = SeparableModelBuilder::<f64>::new(&["c", "d"])
        .function(&["c", "d"], nonlin_fn)
        .partial_deriv("c", nonlin_fn_dc)
        .partial_deriv("d", nonlin_fn_dd)
        .invariant_function(|x| DVector::from_element(x.len(), 1.0))
        .build()?;

    let problem = LevMarProblemBuilder::new()
        .model(&model)
        .x(x)
        .y(y)
        .initial_guess(&[0.2, 0.0])
        .build()?;

    let (solved_problem, report) = LevMarSolver::new().minimize(problem);
    report
        .termination
        .was_successful()
        .then(|| ())
        .ok_or("Termination failed")?;
    let alpha = solved_problem.params();
    let coeff = solved_problem
        .linear_coefficients()
        .ok_or("Linear coeff unwrap failed")?;

    println!("{alpha}");
    println!("{coeff}");

    let res: f64 = coeff.into_iter().sum();

    Ok(res)
}
